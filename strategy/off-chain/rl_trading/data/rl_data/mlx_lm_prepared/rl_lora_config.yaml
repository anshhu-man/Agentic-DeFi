# The path to the local model directory or Hugging Face repo
model: "Qwen/Qwen2.5-3B"

# Whether or not to train (boolean)
train: true

# The fine-tuning method: "lora", "dora", or "full"
fine_tune_type: lora

# The Optimizer with its possible inputs
optimizer: adamw
optimizer_config:
  adamw:
    betas: [0.9, 0.98]
    eps: 1e-6
    weight_decay: 0.1 
    bias_correction: true

# Directory with {train, valid, test}.jsonl files
data: "off-chain/rl_trading/data/rl_data/mlx_lm_prepared"

# The PRNG seed
seed: 42

# Number of layers to fine-tune
num_layers: 12  # Increased to 12 layers - more aggressive fine-tuning

# Minibatch size
batch_size: 1

# Iterations to train for
iters: 150  # 150 since loss converges by then

# Number of validation batches, -1 uses the entire validation set
val_batches: 25

# Adam learning rate
learning_rate: 2e-4  # Aggressive adaptation

# Number of training steps between loss reporting
steps_per_report: 10

# Number of training steps between validations
steps_per_eval: 50

# Load path to resume training with the given adapter weights.
resume_adapter_file: "off-chain/models/trading_model_lora/adapters.safetensors"  # Continue from previous model

# Save/load path for the trained adapter weights.
adapter_path: "off-chain/models/trading_model_rl_lora"

# Save the model every N iterations
save_every: 50

# Evaluate on the test set after training
test: true

# Number of test set batches, -1 uses the entire test set.
test_batches: -1

# Maximum sequence length
max_seq_length: 2048

# Use gradient checkpointing to reduce memory use
grad_checkpoint: true

# LoRA parameters
lora_parameters:
  # Target all aspects of the model for complete control
  keys: ["self_attn.q_proj", "self_attn.k_proj", "self_attn.v_proj", "self_attn.o_proj", "mlp.gate_proj", "mlp.up_proj", "mlp.down_proj"]
  rank: 32  
  scale: 32.0 
  dropout: 0.0

# Token weighting parameters to emphasize exact format and prevent extra output
token_weighting:
  special_tokens: ["RECOMMENDATION", "APE", "IN", "OUT", "NEUTRAL", "Step", "1", "2", "3", "\n", "</s>"]
  weight: 200.0  # Extremely high weight to force the exact tokens since this is a reinforcement learning task on top of a previously fine tuned model

# Schedule
lr_schedule:
  name: cosine_decay
  warmup: 10  # Very short warmup
  warmup_init: 1e-6
  arguments: [2e-4, 150, 1e-6] 